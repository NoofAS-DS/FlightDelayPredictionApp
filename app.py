import json
import numpy as np
import streamlit as st

# ==============================
# 1) ุชุญููู ูุนุงููุงุช ุงููููุฐุฌ
# ==============================
@st.cache_data
def load_model_coeffs(path: str = "lr_coeffs.json"):
    """
    ุชุญููู ูุนุงููุงุช ูููุฐุฌ Logistic Regression ุงููุตุฏูุฑ ูู PySpark.
    ุงูููู ูุชููุน ูุญุชูู:
    {
        "coefficients": [...],
        "intercept": ...,
        "num_features": ...
    }
    """
    with open(path, "r") as f:
        data = json.load(f)
    coeffs = np.array(data["coefficients"], dtype=float)
    intercept = float(data["intercept"])
    num_features = int(data.get("num_features", len(coeffs)))
    return coeffs, intercept, num_features


coeffs, intercept, num_features = load_model_coeffs()

# ==============================
# 2) ุฅุนุฏุงุฏ ุตูุญุฉ Streamlit
# ==============================
st.set_page_config(
    page_title="Flight Delay Prediction",
    page_icon="โ๏ธ",
    layout="centered"
)

st.title("โ๏ธ Flight Delay Prediction App")
st.caption("ูููุฐุฌ ูุจูู ุนูู ูุนุงููุงุช Logistic Regression ุชู ุชุฏุฑูุจูุง ูู PySpark (Demo ุชุนูููู).")

st.markdown(
    """
ูุฐุง ุงูุชุทุจูู **ุชุนูููู** ููุถุญ ููุฑุฉ:
1. ุชุฏุฑูุจ ูููุฐุฌ ุนูู ุจูุงูุงุช ุถุฎูุฉ ุจุงุณุชุฎุฏุงู **PySpark**
2. ุงุณุชุฎุฑุงุฌ **ูุนุงููุงุช ุงููููุฐุฌ (coefficients + intercept)**
3. ุงุณุชุฎุฏุงู ูุฐู ุงููุนุงููุงุช ููุชูุจุค ุฏุงุฎู **Streamlit** ุจุฏูู ุชุดุบูู Spark

> โ๏ธ ููุงุญุธุฉ ูููุฉ:  
> ูู ุงูุชุฏุฑูุจ ุงูุญููููุ ุงุณุชุฎุฏููุง ูุชุฌู ููุฒุงุช ูุจูุฑ `features_scaled` ูุญุชูู ููุฒุงุช ูุซูุฑุฉ  
> (distance, air_time, dep_delay, one-hot encoding, log features, ...).  
> ููุง ุณูุจูู ูุซุงู ูุจุณูุท ูุณุชุฎุฏู 3 ููุฒุงุช ููุท ููุดุฑุญ.
"""
)

st.divider()

# ==============================
# 3) ุฅุฏุฎุงู ุจูุงูุงุช ุงูุฑุญูุฉ ูู ุงููุณุชุฎุฏู
# ==============================
st.subheader("๐ฅ ุฃุฏุฎู ุจูุงูุงุช ุงูุฑุญูุฉ (ูุซุงู ูุจุณูุท)")

col1, col2 = st.columns(2)

with col1:
    distance = st.number_input(
        "ูุณุงูุฉ ุงูุฑุญูุฉ (Miles)",
        min_value=0.0,
        max_value=6000.0,
        value=500.0,
        step=10.0
    )

    dep_delay = st.number_input(
        "ุชุฃุฎูุฑ ุงูุฅููุงุน (ุจุงูุฏูุงุฆูุ ูููู ูููู ุณุงูุจ ูู ุฃููุนุช ุจุฏุฑู)",
        min_value=-60.0,
        max_value=600.0,
        value=0.0,
        step=1.0
    )

with col2:
    air_time = st.number_input(
        "ูุฏุฉ ุงูุทูุฑุงู (Air Time - minutes)",
        min_value=10.0,
        max_value=1000.0,
        value=120.0,
        step=5.0
    )

st.info(
    "ูู ูุณุฎุฉ PySpark ุงูุฃุตููุฉุ ูุฐู ุงูููุฒุงุช ูุชู ุชุญููููุง (Scaling + Encoding) "
    "ุซู ุชุฏุฎู ูู ูุชุฌู features_scaled. ููุง ูุณุชุฎุฏููุง ููุง ูู ููุณุฎุฉ ูุจุณูุทุฉ ููุชูุถูุญ."
)

# ==============================
# 4) ุจูุงุก ูุชุฌู ุงูููุฒุงุช
# ==============================
# โ๏ธ ููู: ูู ุงูุชุฏุฑูุจ ุงูุญููููุ ุชุฑุชูุจ ุงูููุฒุงุช ุฏุงุฎู features_scaled ูุฎุชูู.
# ููุง ูุณุชุฎุฏู ุฃูู 3 ูุนุงููุงุช ูู coeffs ููุซุงู ุชุนูููู:
# ููุชุฑุถ ุฃููุง ุชูุงุจู [distance, air_time, dep_delay]
feature_vector = np.array([distance, air_time, dep_delay], dtype=float)

if len(coeffs) < len(feature_vector):
    st.error(
        f"ุนุฏุฏ ูุนุงููุงุช ุงูููุฏู ({len(coeffs)}) ุฃูู ูู ุนุฏุฏ ุงูููุฒุงุช ูู ูุฐุง ุงููุซุงู ({len(feature_vector)}).\n"
        "ุชุฃูุฏู ูู ุทุฑููุฉ ุชุตุฏูุฑ lr_coeffs.json ุฃู ููููู ุนุฏุฏ ุงูููุฒุงุช."
    )
    st.stop()

used_coeffs = coeffs[: len(feature_vector)]

# ==============================
# 5) ุฏุงูุฉ ุงูุชูุจุค
# ==============================
def predict_delay_proba(x_vec: np.ndarray) -> float:
    """
    ุญุณุงุจ ุงุญุชูุงู ุงูุชุฃุฎูุฑ ุจุงุณุชุฎุฏุงู:
    p = sigmoid(w ยท x + b)
    """
    logit = float(np.dot(used_coeffs, x_vec) + intercept)
    prob = 1.0 / (1.0 + np.exp(-logit))
    return prob


# ==============================
# 6) ุฒุฑ ุงูุชูุจุค
# ==============================
if st.button("๐ฎ ุชูููุน ุงุญุชูุงู ุชุฃุฎุฑ ุงูุฑุญูุฉ"):
    prob_delay = predict_delay_proba(feature_vector)
    prob_on_time = 1 - prob_delay

    st.subheader("๐ ูุชูุฌุฉ ุงูุชูุจุค")

    st.metric(
        label="ุงุญุชูุงู ุชุฃุฎุฑ ุงูุฑุญูุฉ (Delay Probability)",
        value=f"{prob_delay:.2%}"
    )

    st.metric(
        label="ุงุญุชูุงู ุฃู ุชููู ูู ุงูููุช (On Time)",
        value=f"{prob_on_time:.2%}"
    )

    if prob_delay >= 0.5:
        st.error("โ ุงููููุฐุฌ ูุชููุน ุฃู **ุงูุฑุญูุฉ ูุชุฃุฎุฑุฉ ุบุงูุจูุง**.")
    else:
        st.success("โ ุงููููุฐุฌ ูุชููุน ุฃู **ุงูุฑุญูุฉ ูู ุงูููุช ุบุงูุจูุง**.")

    st.caption(
        "ูุฐุง ุงูุชูุจุค ูุจูู ุนูู ูุณุฎุฉ ูุจุณูุทุฉ ูู ุงูููุฒุงุชุ ุงููุฏู ุชุนูููู ูููุณ ูุธุงู ุญุฌุฒ ุญูููู."
    )

st.divider()

# ==============================
# 7) ูุณู ุงุฎุชูุงุฑู: ุนุฑุถ ูุนูููุงุช ุนู ุงููููุฐุฌ
# ==============================
with st.expander("โน๏ธ ุชูุงุตูู ุนู ุงููููุฐุฌ (ููุทูุงุจ / ุงูููุชููู)"):
    st.write(f"๐ข ุนุฏุฏ ูุนุงููุงุช ุงููููุฐุฌ ุงูููู: **{num_features}**")
    st.write(f"๐ ุนุฏุฏ ุงููุนุงููุงุช ุงููุณุชุฎุฏูุฉ ูู ูุฐุง ุงูู Demo: **{len(used_coeffs)}**")
    st.write(f"โ๏ธ ูููุฉ ุงูู Intercept: `{intercept:.4f}`")

    st.markdown(
        """
        **ุงูููุฑุฉ ุงูุนุงูุฉ:**

        - ุชู ุชุฏุฑูุจ ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู **PySpark LogisticRegression** ุนูู ุจูุงูุงุช ุฑุญูุงุช ุทูุฑุงู.
        - ุจุนุฏ ุงูุชุฏุฑูุจุ ุชู ุงุณุชุฎุฑุงุฌ:
            - ุงููุชุฌู `coefficients`
            - ูุงููููุฉ `intercept`
        - ุชู ุญูุธูู ูู ููู `lr_coeffs.json`.
        - ุงูุชุทุจูู ููุง ูุนูุฏ ุงุณุชุฎุฏุงู ููุณ ุงููุนุงููุงุช ููุชูุจุคุ ุจุฏูู ุงูุญุงุฌุฉ ุฅูู ุชุดุบูู Spark.
        """
    )
